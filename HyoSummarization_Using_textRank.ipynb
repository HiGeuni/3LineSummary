{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91656739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import datetime \n",
    "import networkx\n",
    "import json\n",
    "from konlpy.tag import Komoran\n",
    "from kss import split_sentences\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d5616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(content):\n",
    "    #split sentence\n",
    "    sent_list = [sent for sent in split_sentences(''.join(content)) if sent is not None]\n",
    "    return sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea49079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posTagging(sentence):\n",
    "    #pos_tagging\n",
    "    tagger = Komoran()\n",
    "    stopword = set([('있', 'VV'), ('하', 'VV'), ('되', 'VV') ])\n",
    "    posTag = list(filter(\n",
    "            lambda y:y not in stopword and y[1] in ('NNG', 'NNP', 'VV', 'VA'), \n",
    "            tagger.pos(sentence)))\n",
    "    return posTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c71f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawSentence:\n",
    "    def __init__(self, content):\n",
    "        self.content = content\n",
    "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for line in self.content:\n",
    "            ch = self.rgxSplitter.split(line)\n",
    "            print(\"이 것 : \",ch[1::2])\n",
    "            for s in map(lambda a, b: a + b, ch[::2], ch[1::2]):\n",
    "                if not s: \n",
    "                    continue\n",
    "                yield s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48260cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(a, b):\n",
    "        n = len(a.intersection(b))\n",
    "        return n / float(len(a) + len(b) - n) / (math.log(len(a)+1) * math.log(len(b)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4133687",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank:\n",
    "    def __init__(self, window = 5, coef = 1.0, threshold=0.005):\n",
    "        self.graph = None\n",
    "        self.window = window\n",
    "        self.coef = coef\n",
    "        self.threshold = threshold\n",
    "        self.dictCount = 0\n",
    "        self.dictSentence = {}\n",
    "        self.dictSimilarity = {}\n",
    "        self.posTagger = posTagging\n",
    " \n",
    " \n",
    "    def loadSentence(self, sentenceIter):    \n",
    "        setSentence = []\n",
    "        for sent in sentenceIter:\n",
    "            if type(sent) == str:\n",
    "                setSentence.append(set(filter(None, self.posTagger(sent))))\n",
    "            else: \n",
    "                setSentence.append(set(sent))\n",
    "            \n",
    "            self.dictSentence[self.dictCount] = sent\n",
    "            self.dictCount += 1\n",
    "            \n",
    "        for i in range(self.dictCount):\n",
    "            for j in range(i+1, self.dictCount):\n",
    "                s = similarity(setSentence[i], setSentence[j])\n",
    "                if s < self.threshold: continue\n",
    "                self.dictSimilarity[i, j] = s\n",
    "    \n",
    "    def build(self):\n",
    "        self.graph = networkx.Graph()\n",
    "        self.graph.add_nodes_from(self.dictSentence.keys())\n",
    "        for (a, b), n in self.dictSimilarity.items():\n",
    "            self.graph.add_edge(a, b, weight=n*self.coef + (1-self.coef))\n",
    " \n",
    "    def rank(self):\n",
    "        return networkx.pagerank(self.graph, weight='weight')\n",
    " \n",
    "\n",
    "    def summarize(self, ratio = 0.333):\n",
    "        r = self.rank()\n",
    "        ks = sorted(r, key=r.get, reverse=True)[:int(len(r)*ratio)]\n",
    "        return ' '.join(map(lambda k:self.dictSentence[k], sorted(ks)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "409a4d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_contents(x):\n",
    "    tr = TextRank(5, 1.0, 0.005) #window, coef, threshold\n",
    "\n",
    "    tr.loadSentence(tokenize(x))\n",
    "\n",
    "    tr.build()\n",
    "    ranks = tr.rank()\n",
    "    return tr.summarize(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee003410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'나경원 한국당 원내대표는 \"오늘 가장 강하게 요청한 것은 특검법이었다\"고 말했다. 반면 홍영표 민주당 원내대표는 말을 아꼈다.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarise_contents(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88dc95e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data.json\", 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab3818f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = data[1][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed510a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd32a432",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summarise_contents(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
